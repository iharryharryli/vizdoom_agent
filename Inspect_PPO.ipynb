{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import algo\n",
    "from arguments import get_args\n",
    "from envs import make_vec_envs_ViZDoom, make_vec_envs\n",
    "from model import Policy\n",
    "from storage import RolloutStorage\n",
    "from utils import get_vec_normalize\n",
    "from visualize import visdom_plot\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../random_record/\"\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "reward_history = os.path.join(result_dir, \"reward_history\")\n",
    "loss_history = os.path.join(result_dir, \"loss_history\")\n",
    "parameter_save = os.path.join(result_dir, \"parameter.json\")\n",
    "env_parameter_save = os.path.join(result_dir, \"env.json\")\n",
    "fileL = [reward_history, loss_history, parameter_save, env_parameter_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove old record files\n",
    "for f in fileL:\n",
    "    try:\n",
    "        os.remove(f)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "\n",
    "def ppo_hyper():\n",
    "    args.algo = \"ppo\"\n",
    "    args.use_gae = False\n",
    "    args.lr = 1e-5\n",
    "    args.value_loss_coef = 1.0\n",
    "    args.num_processes = 8\n",
    "    args.num_steps = 512\n",
    "    args.num_mini_batch = 4\n",
    "    args.entropy_coef = 0.01\n",
    "    args.gamma = 1.0\n",
    "    args.ppo_epoch = 10\n",
    "    args.clip_param = 0.1\n",
    "\n",
    "def a2c_hyper():\n",
    "    args.algo = \"a2c\"\n",
    "    args.gamma = 1.0\n",
    "    args.num_steps = 512\n",
    "    args.num_processes = 8\n",
    "    args.entropy_coef = 0.01\n",
    "    args.use_adam = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(add_timestep=False, algo='a2c', alpha=0.99, clip_param=0.2, cuda=True, entropy_coef=0.01, env_name='PongNoFrameskip-v4', eps=1e-05, eval_interval=None, gamma=1.0, log_dir='/tmp/gym/', log_interval=10, lr=0.0007, max_grad_norm=0.5, no_cuda=False, num_frames=10000000.0, num_mini_batch=32, num_processes=8, num_steps=512, port=8097, ppo_epoch=4, recurrent_policy=False, save_dir='./trained_models/', save_interval=100, seed=1, tau=0.95, use_adam=True, use_gae=False, value_loss_coef=0.5, vis=False, vis_interval=100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_hyper()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {}\n",
    "parameters['algo'] = args.algo\n",
    "parameters['gamma'] = args.gamma\n",
    "parameters['num_steps'] = args.num_steps\n",
    "parameters['num_processes'] = args.num_processes\n",
    "parameters['value_loss_coef'] = args.value_loss_coef\n",
    "parameters['eps'] = args.eps\n",
    "parameters['entropy_coef'] = args.entropy_coef\n",
    "parameters['lr'] = args.lr\n",
    "parameters['use_gae'] = args.use_gae\n",
    "parameters['max_grad_norm'] = args.max_grad_norm\n",
    "parameters['seed'] = args.seed\n",
    "\n",
    "if parameters['algo'] == \"a2c\":\n",
    "    parameters['alpha'] = args.alpha\n",
    "    parameters['use_adam'] = args.use_adam\n",
    "elif parameters['algo'] == \"ppo\":\n",
    "    parameters['clip_param'] = args.clip_param\n",
    "    parameters['ppo_epoch'] = args.ppo_epoch\n",
    "    parameters['num_mini_batch'] = args.num_mini_batch\n",
    "\n",
    "if parameters['use_gae']:\n",
    "    parameters['tau'] = args.tau\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_arg = {\n",
    "    \"reward_scale\": 0.01,\n",
    "    \"use_rgb\": True,\n",
    "    \"use_depth\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(parameters, open(parameter_save, \"w\"))\n",
    "json.dump(env_arg, open(env_parameter_save, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_updates = int(args.num_frames) // args.num_steps // args.num_processes\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(1)\n",
    "device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n",
    "\n",
    "envs = make_vec_envs_ViZDoom(args.seed, args.num_processes, device, **env_arg)\n",
    "\n",
    "actor_critic = Policy(envs.observation_space.shape, envs.action_space,\n",
    "    base_kwargs={'recurrent': args.recurrent_policy})\n",
    "actor_critic.to(device)\n",
    "\n",
    "if args.algo == 'a2c':\n",
    "    agent = algo.A2C_ACKTR(actor_critic, args.value_loss_coef,\n",
    "                               args.entropy_coef, lr=args.lr,\n",
    "                               eps=args.eps, alpha=args.alpha,\n",
    "                               max_grad_norm=args.max_grad_norm,\n",
    "                               use_adam=args.use_adam)\n",
    "else:\n",
    "    agent = algo.PPO(actor_critic, args.clip_param, args.ppo_epoch, args.num_mini_batch,\n",
    "                         args.value_loss_coef, args.entropy_coef, lr=args.lr,\n",
    "                               eps=args.eps,\n",
    "                               max_grad_norm=args.max_grad_norm)\n",
    "\n",
    "rollouts = RolloutStorage(args.num_steps, args.num_processes,\n",
    "                    envs.observation_space.shape, envs.action_space,\n",
    "                    actor_critic.recurrent_hidden_state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = envs.reset()\n",
    "rollouts.obs[0].copy_(obs)\n",
    "rollouts.to(device)\n",
    "\n",
    "recent_count = 50\n",
    "episode_lengths = deque(maxlen=recent_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 updates: avg length = 345.0\n",
      "8192 updates: avg length = 373.1764705882353\n",
      "12288 updates: avg length = 392.2857142857143\n",
      "16384 updates: avg length = 399.7837837837838\n"
     ]
    }
   ],
   "source": [
    "for j in range(num_updates):\n",
    "    for step in range(args.num_steps):\n",
    "        # Sample actions\n",
    "        with torch.no_grad():\n",
    "            value, action, action_log_prob, recurrent_hidden_states = actor_critic.act(\n",
    "                    rollouts.obs[step],\n",
    "                    rollouts.recurrent_hidden_states[step],\n",
    "                    rollouts.masks[step])\n",
    "\n",
    "        # Obser reward and next obs\n",
    "        obs, reward, done, infos = envs.step(action)\n",
    "\n",
    "        for info in infos:\n",
    "            if 'Episode_Total_Len' in info.keys():\n",
    "                episode_lengths.append(info['Episode_Total_Len'])\n",
    "\n",
    "        # If done then clean the history of observations.\n",
    "        masks = torch.FloatTensor([[0.0] if done_ else [1.0]\n",
    "                                   for done_ in done])\n",
    "        rollouts.insert(obs, recurrent_hidden_states, action, action_log_prob, value, reward, masks)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        next_value = actor_critic.get_value(rollouts.obs[-1],\n",
    "                                            rollouts.recurrent_hidden_states[-1],\n",
    "                                            rollouts.masks[-1]).detach()\n",
    "\n",
    "    rollouts.compute_returns(next_value, args.use_gae, args.gamma, args.tau)\n",
    "\n",
    "    value_loss, action_loss, dist_entropy = agent.update(rollouts)\n",
    "\n",
    "    rollouts.after_update()\n",
    "    \n",
    "    total_num_steps = (j + 1) * args.num_processes * args.num_steps\n",
    "    \n",
    "    with open(loss_history, 'a') as the_file:\n",
    "        the_file.write(\"{} {} {} {} \\n\".format(total_num_steps, value_loss, action_loss, dist_entropy))\n",
    "    \n",
    "    if len(episode_lengths) > 0:\n",
    "        print(\"{} updates: avg length = {}\".format(total_num_steps, \n",
    "                                                   np.mean(episode_lengths)))\n",
    "        \n",
    "        with open(reward_history, 'a') as the_file:\n",
    "            the_file.write('{} {} \\n'.format(total_num_steps, \n",
    "                                               np.mean(episode_lengths)))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = os.path.join(result_dir, \"model.save\")\n",
    "torch.save(actor_critic.state_dict(), MODEL_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
